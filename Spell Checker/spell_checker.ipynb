{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File input and unique data separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words  1115585\n",
      "Total number of unique words  32198\n",
      "['freesoil', 'rustling', 'oven', 'buttock', 'habit', 'franklin_', 'zakharych', 'scant', 'selle', 'thudding', 'tour', 'furieuse', 'significant', 'citizen', 'hopelessly', 'audible', 'outbreaks', 'moistened', 'suave', 'lacrymal', 'everybody', 'thinkers', 'underline', 'engendered', '_granulomata_', 'internode', 'raft', 'promoters', '1680', '1760', 'hey', 'adults', 'solemnity', 'suggest', 'burnoose', 'foaming', '2003', 'lambskin', 'initiatives', 'apraksins', 'wicker', 'dot', 'refugees', 'ta', 'elets', 'study', 'amputating', '_endothelioma_', 'introduction', 'ulyulyulyu', 'amuses', 'anti', 'solidified', 'correcting', 'roses', 'spain', 'turtle', 'regent', 'try', 'butts', 'rashes', 'irresistible', 'seeming', 'persevered', 'incisors', 'teamster', 'unquestioning', 'eyeglasses', '281', 'chagrined', 'scathing', 'suffice', 'hypodermic', 'palsies', '99ff', 'tproo', 'tuberculosis_', 'tag', 'wherefore', 'sanguinary', 'wonderful', 'confounded', 'decomposes', 'mightier', 'appalling', 'summon', 'justifying', 'weighed', 'contained', 'jocular', 'noisome', 'wearing', 'azov', '_senile', 'selections', 'ingesting', 'moscovites', '_history', 'ossificans', 'boost']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "vocab = []\n",
    "\n",
    "with open('big.txt','r') as fd:\n",
    "    lines = fd.readlines()\n",
    "    for line in lines:\n",
    "        words += re.findall(r'\\w+', line.lower())\n",
    "\n",
    "print(\"Total number of words \",len(words))\n",
    "vocab = list(set(words))\n",
    "print(\"Total number of unique words \",len(vocab))\n",
    "\n",
    "print(vocab[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distribution of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9773"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count(\"is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32198 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32198/32198 [11:23<00:00, 47.09it/s]\n"
     ]
    }
   ],
   "source": [
    "probability_distribution = dict()\n",
    "\n",
    "for word in tqdm(vocab):\n",
    "    probability_distribution[word] = float(words.count(word) / len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32198\n",
      "freesoil : 8.963906829152417e-07\n",
      "rustling : 6.2747347804066925e-06\n",
      "oven : 6.2747347804066925e-06\n",
      "buttock : 2.061698570705056e-05\n",
      "habit : 4.9301487560338295e-05\n",
      "franklin_ : 8.963906829152417e-07\n",
      "zakharych : 1.7927813658304835e-06\n",
      "scant : 3.585562731660967e-06\n",
      "selle : 8.963906829152417e-07\n",
      "thudding : 8.963906829152417e-07\n",
      "the 0.07154004401278254\n"
     ]
    }
   ],
   "source": [
    "print(len(probability_distribution))\n",
    "\n",
    "for word in vocab[:10]:\n",
    "    print(word,\":\",probability_distribution[word])\n",
    "\n",
    "print(\"the\",probability_distribution[\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(word):\n",
    "    output = []\n",
    "    for i in range(len(word)+1):\n",
    "        l = word[:i]\n",
    "        r = word[i:]\n",
    "        output.append([l,r])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'happy'],\n",
       " ['h', 'appy'],\n",
       " ['ha', 'ppy'],\n",
       " ['hap', 'py'],\n",
       " ['happ', 'y'],\n",
       " ['happy', '']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = split(\"happy\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">1. Deletion</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thae -> the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['appy', 'hppy', 'hapy', 'hapy', 'happ', 'happy']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete(word):\n",
    "    output = []\n",
    "\n",
    "    for l,r in split(word):\n",
    "        output+=[l+r[1:]]\n",
    "\n",
    "    return output\n",
    "\n",
    "delete(\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">2. Swap</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teh -> the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahppy', 'hpapy', 'happy', 'hapyp']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def swap(word):\n",
    "    output = []\n",
    "\n",
    "    for l,r in split(word):\n",
    "        if len(r)>1:\n",
    "            output+=[l+r[1]+r[0]+r[2:]]\n",
    "\n",
    "    return output\n",
    "\n",
    "swap(\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">3. Replace</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tha -> the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aappy',\n",
       " 'bappy',\n",
       " 'cappy',\n",
       " 'dappy',\n",
       " 'eappy',\n",
       " 'fappy',\n",
       " 'gappy',\n",
       " 'happy',\n",
       " 'iappy',\n",
       " 'jappy',\n",
       " 'kappy',\n",
       " 'lappy',\n",
       " 'mappy',\n",
       " 'nappy',\n",
       " 'oappy',\n",
       " 'pappy',\n",
       " 'qappy',\n",
       " 'rappy',\n",
       " 'sappy',\n",
       " 'tappy',\n",
       " 'uappy',\n",
       " 'vappy',\n",
       " 'wappy',\n",
       " 'xappy',\n",
       " 'yappy',\n",
       " 'zappy',\n",
       " 'happy',\n",
       " 'hbppy',\n",
       " 'hcppy',\n",
       " 'hdppy',\n",
       " 'heppy',\n",
       " 'hfppy',\n",
       " 'hgppy',\n",
       " 'hhppy',\n",
       " 'hippy',\n",
       " 'hjppy',\n",
       " 'hkppy',\n",
       " 'hlppy',\n",
       " 'hmppy',\n",
       " 'hnppy',\n",
       " 'hoppy',\n",
       " 'hpppy',\n",
       " 'hqppy',\n",
       " 'hrppy',\n",
       " 'hsppy',\n",
       " 'htppy',\n",
       " 'huppy',\n",
       " 'hvppy',\n",
       " 'hwppy',\n",
       " 'hxppy',\n",
       " 'hyppy',\n",
       " 'hzppy',\n",
       " 'haapy',\n",
       " 'habpy',\n",
       " 'hacpy',\n",
       " 'hadpy',\n",
       " 'haepy',\n",
       " 'hafpy',\n",
       " 'hagpy',\n",
       " 'hahpy',\n",
       " 'haipy',\n",
       " 'hajpy',\n",
       " 'hakpy',\n",
       " 'halpy',\n",
       " 'hampy',\n",
       " 'hanpy',\n",
       " 'haopy',\n",
       " 'happy',\n",
       " 'haqpy',\n",
       " 'harpy',\n",
       " 'haspy',\n",
       " 'hatpy',\n",
       " 'haupy',\n",
       " 'havpy',\n",
       " 'hawpy',\n",
       " 'haxpy',\n",
       " 'haypy',\n",
       " 'hazpy',\n",
       " 'hapay',\n",
       " 'hapby',\n",
       " 'hapcy',\n",
       " 'hapdy',\n",
       " 'hapey',\n",
       " 'hapfy',\n",
       " 'hapgy',\n",
       " 'haphy',\n",
       " 'hapiy',\n",
       " 'hapjy',\n",
       " 'hapky',\n",
       " 'haply',\n",
       " 'hapmy',\n",
       " 'hapny',\n",
       " 'hapoy',\n",
       " 'happy',\n",
       " 'hapqy',\n",
       " 'hapry',\n",
       " 'hapsy',\n",
       " 'hapty',\n",
       " 'hapuy',\n",
       " 'hapvy',\n",
       " 'hapwy',\n",
       " 'hapxy',\n",
       " 'hapyy',\n",
       " 'hapzy',\n",
       " 'happa',\n",
       " 'happb',\n",
       " 'happc',\n",
       " 'happd',\n",
       " 'happe',\n",
       " 'happf',\n",
       " 'happg',\n",
       " 'happh',\n",
       " 'happi',\n",
       " 'happj',\n",
       " 'happk',\n",
       " 'happl',\n",
       " 'happm',\n",
       " 'happn',\n",
       " 'happo',\n",
       " 'happp',\n",
       " 'happq',\n",
       " 'happr',\n",
       " 'happs',\n",
       " 'happt',\n",
       " 'happu',\n",
       " 'happv',\n",
       " 'happw',\n",
       " 'happx',\n",
       " 'happy',\n",
       " 'happz',\n",
       " 'happya',\n",
       " 'happyb',\n",
       " 'happyc',\n",
       " 'happyd',\n",
       " 'happye',\n",
       " 'happyf',\n",
       " 'happyg',\n",
       " 'happyh',\n",
       " 'happyi',\n",
       " 'happyj',\n",
       " 'happyk',\n",
       " 'happyl',\n",
       " 'happym',\n",
       " 'happyn',\n",
       " 'happyo',\n",
       " 'happyp',\n",
       " 'happyq',\n",
       " 'happyr',\n",
       " 'happys',\n",
       " 'happyt',\n",
       " 'happyu',\n",
       " 'happyv',\n",
       " 'happyw',\n",
       " 'happyx',\n",
       " 'happyy',\n",
       " 'happyz']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace(word):\n",
    "    output = []\n",
    "\n",
    "    for l,r in split(word):\n",
    "        for ch in characters:\n",
    "            output += [l+ch+r[1:]]\n",
    "\n",
    "    return output\n",
    "\n",
    "replace(\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">4. Insertion</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "th -> the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahappy',\n",
       " 'bhappy',\n",
       " 'chappy',\n",
       " 'dhappy',\n",
       " 'ehappy',\n",
       " 'fhappy',\n",
       " 'ghappy',\n",
       " 'hhappy',\n",
       " 'ihappy',\n",
       " 'jhappy',\n",
       " 'khappy',\n",
       " 'lhappy',\n",
       " 'mhappy',\n",
       " 'nhappy',\n",
       " 'ohappy',\n",
       " 'phappy',\n",
       " 'qhappy',\n",
       " 'rhappy',\n",
       " 'shappy',\n",
       " 'thappy',\n",
       " 'uhappy',\n",
       " 'vhappy',\n",
       " 'whappy',\n",
       " 'xhappy',\n",
       " 'yhappy',\n",
       " 'zhappy',\n",
       " 'haappy',\n",
       " 'hbappy',\n",
       " 'hcappy',\n",
       " 'hdappy',\n",
       " 'heappy',\n",
       " 'hfappy',\n",
       " 'hgappy',\n",
       " 'hhappy',\n",
       " 'hiappy',\n",
       " 'hjappy',\n",
       " 'hkappy',\n",
       " 'hlappy',\n",
       " 'hmappy',\n",
       " 'hnappy',\n",
       " 'hoappy',\n",
       " 'hpappy',\n",
       " 'hqappy',\n",
       " 'hrappy',\n",
       " 'hsappy',\n",
       " 'htappy',\n",
       " 'huappy',\n",
       " 'hvappy',\n",
       " 'hwappy',\n",
       " 'hxappy',\n",
       " 'hyappy',\n",
       " 'hzappy',\n",
       " 'haappy',\n",
       " 'habppy',\n",
       " 'hacppy',\n",
       " 'hadppy',\n",
       " 'haeppy',\n",
       " 'hafppy',\n",
       " 'hagppy',\n",
       " 'hahppy',\n",
       " 'haippy',\n",
       " 'hajppy',\n",
       " 'hakppy',\n",
       " 'halppy',\n",
       " 'hamppy',\n",
       " 'hanppy',\n",
       " 'haoppy',\n",
       " 'happpy',\n",
       " 'haqppy',\n",
       " 'harppy',\n",
       " 'hasppy',\n",
       " 'hatppy',\n",
       " 'hauppy',\n",
       " 'havppy',\n",
       " 'hawppy',\n",
       " 'haxppy',\n",
       " 'hayppy',\n",
       " 'hazppy',\n",
       " 'hapapy',\n",
       " 'hapbpy',\n",
       " 'hapcpy',\n",
       " 'hapdpy',\n",
       " 'hapepy',\n",
       " 'hapfpy',\n",
       " 'hapgpy',\n",
       " 'haphpy',\n",
       " 'hapipy',\n",
       " 'hapjpy',\n",
       " 'hapkpy',\n",
       " 'haplpy',\n",
       " 'hapmpy',\n",
       " 'hapnpy',\n",
       " 'hapopy',\n",
       " 'happpy',\n",
       " 'hapqpy',\n",
       " 'haprpy',\n",
       " 'hapspy',\n",
       " 'haptpy',\n",
       " 'hapupy',\n",
       " 'hapvpy',\n",
       " 'hapwpy',\n",
       " 'hapxpy',\n",
       " 'hapypy',\n",
       " 'hapzpy',\n",
       " 'happay',\n",
       " 'happby',\n",
       " 'happcy',\n",
       " 'happdy',\n",
       " 'happey',\n",
       " 'happfy',\n",
       " 'happgy',\n",
       " 'happhy',\n",
       " 'happiy',\n",
       " 'happjy',\n",
       " 'happky',\n",
       " 'happly',\n",
       " 'happmy',\n",
       " 'happny',\n",
       " 'happoy',\n",
       " 'happpy',\n",
       " 'happqy',\n",
       " 'happry',\n",
       " 'happsy',\n",
       " 'happty',\n",
       " 'happuy',\n",
       " 'happvy',\n",
       " 'happwy',\n",
       " 'happxy',\n",
       " 'happyy',\n",
       " 'happzy',\n",
       " 'happya',\n",
       " 'happyb',\n",
       " 'happyc',\n",
       " 'happyd',\n",
       " 'happye',\n",
       " 'happyf',\n",
       " 'happyg',\n",
       " 'happyh',\n",
       " 'happyi',\n",
       " 'happyj',\n",
       " 'happyk',\n",
       " 'happyl',\n",
       " 'happym',\n",
       " 'happyn',\n",
       " 'happyo',\n",
       " 'happyp',\n",
       " 'happyq',\n",
       " 'happyr',\n",
       " 'happys',\n",
       " 'happyt',\n",
       " 'happyu',\n",
       " 'happyv',\n",
       " 'happyw',\n",
       " 'happyx',\n",
       " 'happyy',\n",
       " 'happyz']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insertion(word):\n",
    "    output = []\n",
    "\n",
    "    for l,r in split(word):\n",
    "        for ch in characters:\n",
    "            output += [l+ch+r]\n",
    "\n",
    "    return output\n",
    "\n",
    "insertion(\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\">Prediction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'that', 'than', 'tea', 'ha']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_word(word):\n",
    "\n",
    "    # get all possible solutions\n",
    "    possible_solutions = []\n",
    "    possible_solutions.extend(delete(word))\n",
    "    possible_solutions.extend(swap(word))\n",
    "    possible_solutions.extend(replace(word))\n",
    "    possible_solutions.extend(insertion(word))\n",
    "\n",
    "    # get unique solutions\n",
    "    possible_solutions = list(set(possible_solutions))\n",
    "\n",
    "    # search that words are also in vocab\n",
    "    solutions = []\n",
    "\n",
    "    for word in possible_solutions:\n",
    "        if word in probability_distribution.keys():\n",
    "            solutions.append([word, probability_distribution[word]])\n",
    "    \n",
    "    # sort based on frequency of occurrence\n",
    "    solutions.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # create the answer list\n",
    "    answer = []\n",
    "    for word in range(len(solutions)-1,-1,-1):\n",
    "        answer.append(solutions[word][0])\n",
    "    \n",
    "    return answer[0:5]\n",
    "\n",
    "check_word(\"tha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'haney']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word(\"hapey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so', 'god', 'son', 'sad', 'sold']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word(\"sod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['necessary']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word(\"necessory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
